{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc0702d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required modules\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39f4f3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52015cdff7f440eea381e7358fdea2ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm, notebook\n",
    "notebook.tqdm().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c16e76fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small adjustments to default style of plots, making sure it's readable and colorblind-friendly everywhere\n",
    "plt.style.use('seaborn-colorblind')\n",
    "plt.rcParams.update({'font.size' : 12.5,\n",
    "                     'figure.figsize':(25,7)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebe108a",
   "metadata": {},
   "source": [
    "Get the path to retrieve data from local folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e09f3df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jules: \n",
    "#Small sample\n",
    "path = r'/Users/jules/kDrive/onedrive/Documents_Onedrive/EPFL/MA3/ADA/Project/Dataset/'\n",
    "\n",
    "#Big sample\n",
    "#path = r'C:\\Users\\jules\\kDrive\\onedrive\\Documents_Onedrive\\EPFL\\MA3\\ADA\\Project\\Dataset\\BIG_SAMPLE'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f0feba",
   "metadata": {},
   "source": [
    "#### Using the provided csv file to link qids with meaningful names for speakers metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fb69b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lookup = pd.read_csv('wikidata_labels_descriptions_quotebank.csv.bz2',compression = 'bz2',index_col='QID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cdfc33",
   "metadata": {},
   "source": [
    "## Speakers_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed1b267",
   "metadata": {},
   "source": [
    "### Retrieve all americans politicians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75b45ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop NaNs in occupation\n",
    "def get_polUS(df_speakers):\n",
    "    df_speakers.dropna(axis=0,inplace=True,subset=['occupation','nationality'])\n",
    "    assert df_speakers['occupation'].isna().sum() == 0\n",
    "    assert df_speakers['nationality'].isna().sum() == 0\n",
    "    \n",
    "    pol_cond = df_speakers['occupation'].apply(lambda x : any(item in 'Q82955' for item in x)) \n",
    "    us_cond = df_speakers['nationality'].apply(lambda x : any(item in 'Q30' for item in x)) #Q142 for french \n",
    "\n",
    "    df_polUS = df_speakers.loc[us_cond & pol_cond]\n",
    "\n",
    "    return df_polUS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c3c0c6",
   "metadata": {},
   "source": [
    "### Create the age column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58161c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime\n",
    "\n",
    "def get_age(df_speakers):\n",
    "    \n",
    "    #Define the function to calculate the age of speakers \n",
    "    def calculate_age(born):\n",
    "        today = date.today()\n",
    "        return today.year - born.year - ((today.month, today.day) < (born.month, born.day))\n",
    "    \n",
    "    def str2datetime(string):\n",
    "        date_format = '+%Y-%m-%dT%H:%M:%SZ'\n",
    "        try:\n",
    "            dt = datetime.strptime(string,date_format)\n",
    "        except:\n",
    "            dt = None\n",
    "        return dt\n",
    "    \n",
    "    df = df_speakers.copy()\n",
    "    \n",
    "    #Convert list into string\n",
    "    df['date_of_birth'] = df['date_of_birth'].apply(lambda x: x[0] if x is not None else None)\n",
    "    \n",
    "    #Retrieve date_of_birth with 00-00 as month/day and replace it by the 01-01\n",
    "    df['date_of_birth']=df['date_of_birth'].apply(lambda x: x.replace('-00','-01') if x is not None else None)\n",
    "\n",
    "    #Transform date_of_birth from string to datetime\n",
    "    df['date_of_birth'] = df['date_of_birth'].apply(lambda x: str2datetime(x)if x is not None else None)\n",
    "    \n",
    "    # Calculate the age of each speakers\n",
    "    df['age'] =  df['date_of_birth'].apply(lambda x: calculate_age(x) if x is not None else None)\n",
    "    \n",
    "    #Detect ages that are incoherent and drop the rows \n",
    "    \n",
    "    df.drop(df[df['age']<15].index, inplace=True)\n",
    "    df.drop(df[df['age']>110].index, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e8005c",
   "metadata": {},
   "source": [
    "### Create a column called \"bi_party\" containg either \"Democrate\" or \"Republican\" party"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ef866f",
   "metadata": {},
   "source": [
    "QID Republican : Q29468\n",
    "\n",
    "QID Democratic Q29552"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f31eb408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bi_party(df_speakers):\n",
    "    df = df_speakers.copy()\n",
    "    \n",
    "    demo_cond = df_speakers['party'].apply(lambda x : any(item in 'Q29552' for item in x) if x is not None else False)\n",
    "    repu_cond = df_speakers['party'].apply(lambda x : any(item in 'Q29468' for item in x) if x is not None else False)\n",
    "    \n",
    "    df['bi_party']=None\n",
    "    \n",
    "    df.loc[demo_cond,'bi_party'] = 'Democrat'\n",
    "    df.loc[repu_cond,'bi_party'] = 'Republican'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe70033",
   "metadata": {},
   "source": [
    "##  Prepare the dataset for regressions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "786c5104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speakers_metadata(df_speakers):\n",
    "    df = get_polUS(df_speakers)\n",
    "    # shift column 'label' to first position\n",
    "    first_column = df.pop('label')\n",
    "    # insert column using insert(position,column_name,first_column) function\n",
    "    df.insert(0, 'label', first_column)\n",
    "    \n",
    "    #Create the age column\n",
    "    df = get_age(df)\n",
    "    \n",
    "    #Create the bi-party column\n",
    "    df = get_bi_party(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a260601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ready_for_lr(file_path,df_speakers):\n",
    "\n",
    "    #Import quotes dataset (classified)\n",
    "    df_quotes = pd.read_json(file_path,compression = 'bz2',lines = True)\n",
    "\n",
    "    #Choose the first QID that is associated with (to be improved)\n",
    "    df_quotes['qid_unique'] = df_quotes['qids'].apply(lambda x: x[0])\n",
    "\n",
    "    #Drop the useless columns \n",
    "    col_useless = ['qids','probas','numOccurrences','phase']\n",
    "    df_quotes.drop(col_useless,axis=1,inplace=True)\n",
    "    \n",
    "    # shift column 'label' to first position\n",
    "    first_column = df_quotes.pop('qid_unique')\n",
    "    # insert column using insert(position,column_name,first_column) function\n",
    "    df_quotes.insert(3, 'qid_unique', first_column)\n",
    "    \n",
    "    #Merge the quote with the speakers metadata\n",
    "    df_quotes_merged = df_quotes.merge(df_speakers,how='inner',left_on='qid_unique', right_on='id')\n",
    "    \n",
    "    return df_quotes_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6fe5212",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the speakers metadata\n",
    "path = r'/Users/jules/kDrive/onedrive/Documents_Onedrive/EPFL/MA3/ADA/Project/Dataset/'\n",
    "df_speakers = pd.read_parquet(path+'speaker_attributes.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b40a8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speakers_pol=speakers_metadata(df_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae43a269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process the sample\n",
    "\n",
    "path = r'/Users/jules/kDrive/onedrive/Documents_Onedrive/EPFL/MA3/ADA/Project/Dataset/BIG_SAMPLE/'\n",
    "file_path = path+'Sample_2019_classified.json.bz2'\n",
    "\n",
    "#path = r'/Users/jules/kDrive/onedrive/Documents_Onedrive/EPFL/MA3/ADA/Project/Dataset/'\n",
    "#file_path = path+'Sample_classified_1Mio_v1.json.bz2'\n",
    "\n",
    "df_speakers_pol = speakers_metadata(df_speakers)\n",
    "df = ready_for_lr(file_path, df_speakers_pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dacdac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export the dataframe df_speakers\n",
    "df_speakers_pol.to_json(path+'/Results_LR/df_speakers_pol.json.bz2',compression='bz2',lines=True,orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e043cfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate files by year to create a unique dataset\n",
    "\n",
    "path = r'/Users/jules/kDrive/onedrive/Documents_Onedrive/EPFL/MA3/ADA/Project/Dataset/BIG_SAMPLE/Results_LR/'\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for year in range(2015,2021,1):\n",
    "    file_path = path +'df_LR_'+ str(year)+'.json.bz2'\n",
    "    try:\n",
    "        df_temp = pd.read_json(file_path,compression = 'bz2',lines = True)\n",
    "        df = pd.concat([df, df_temp])\n",
    "    except:\n",
    "        print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a96213",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export the unique dataset for all the years\n",
    "\n",
    "df.to_json(path+'df_all.json.bz2',compression='bz2',lines=True,orient=\"records\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
