{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "804c1934",
   "metadata": {},
   "source": [
    "# Quotes classification\n",
    "\n",
    "In this notebook, we treat each quote of the corpus and assign them a binary score determining if the quote is formal or colloquial according the dictionnary of english contractions to avoid in wikipedia articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f695b871",
   "metadata": {},
   "source": [
    "## Packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "801bcdeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "287dc2273d044fc4b4ae480c421b5227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#packages\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, notebook\n",
    "notebook.tqdm().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bfc9939",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to check if strin is contained and update dico\n",
    "def isinside1(test_string,test_list):\n",
    "    global dico\n",
    "    res = [ele for ele in test_list if(ele in test_string)]\n",
    "    #print(res)\n",
    "    if res:\n",
    "        for ele in res:\n",
    "            i= test_list.index(ele)\n",
    "            dico[\"occurences\"].loc[i]= dico[\"occurences\"].loc[i]+1\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def isinside2(test_string,test_list):\n",
    "    if any(ext in test_string for ext in test_list):\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a5743b",
   "metadata": {},
   "source": [
    "## Dictionnary loading\n",
    "The dictionnary is compiled in the notebook `contractions_dictionary.ipynb` and is based on the [Wikipedia English contractions list](https://en.wikipedia.org/wiki/Wikipedia:List_of_English_contractions).<br>\n",
    "A column name \"occurences\" is created in order to count how much time a word is detected.<br>\n",
    "A list is made from the dictionary words for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fc7bea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dico= pd.read_pickle(\"./english_contractions.pkl\")\n",
    "dico[\"occurences\"]=0\n",
    "dicolist= dico[\"word\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc77e15",
   "metadata": {},
   "source": [
    "## Quotebank sample loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07eea2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_json(\"../../../Sample_classified_1Mio_v1.json.bz2\",compression=\"bz2\",lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7794903",
   "metadata": {},
   "source": [
    "### Quotes formatting for comparison : lowercase and space at the beginning and end\n",
    "Note that tokenisation has not been used as some of the words or the dictionary consist in several tokens (for exemple, isn't is composed of tokens \"is\" and \"n't\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a88abb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2efcd960b0d64865869ca843a5f7b101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/668534 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_tested_quotes= df[\"quotation\"].progress_apply(lambda x : \" \"+x.lower()+\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea21205",
   "metadata": {},
   "source": [
    "## Classification using the full dictionary\n",
    "The dataset quotes are classified a first time using the full dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73beb55a",
   "metadata": {},
   "source": [
    "### Classifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd3b1516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3dca1323264660bef8b98b32777dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/668534 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasantacroce/opt/anaconda3/envs/adaenv/lib/python3.8/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "df[\"colloquial\"]= df_tested_quotes.progress_apply(lambda x : isinside1(x,dicolist))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f7525f",
   "metadata": {},
   "source": [
    "### Quotes statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0bf1b484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numOccurrences</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>delta_p</th>\n",
       "      <th>year</th>\n",
       "      <th>colloquial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>668534.00000</td>\n",
       "      <td>668534.000000</td>\n",
       "      <td>668534.000000</td>\n",
       "      <td>668534.000000</td>\n",
       "      <td>668534.000000</td>\n",
       "      <td>668534.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.55898</td>\n",
       "      <td>0.818245</td>\n",
       "      <td>0.161096</td>\n",
       "      <td>0.657149</td>\n",
       "      <td>2017.536327</td>\n",
       "      <td>0.383233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22.64603</td>\n",
       "      <td>0.095738</td>\n",
       "      <td>0.081709</td>\n",
       "      <td>0.173361</td>\n",
       "      <td>1.770882</td>\n",
       "      <td>0.486175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.500100</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.747400</td>\n",
       "      <td>0.093400</td>\n",
       "      <td>0.521900</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.830100</td>\n",
       "      <td>0.152600</td>\n",
       "      <td>0.674900</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.00000</td>\n",
       "      <td>0.897300</td>\n",
       "      <td>0.221900</td>\n",
       "      <td>0.802200</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12086.00000</td>\n",
       "      <td>0.990800</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.982100</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       numOccurrences             p1             p2        delta_p  \\\n",
       "count    668534.00000  668534.000000  668534.000000  668534.000000   \n",
       "mean          3.55898       0.818245       0.161096       0.657149   \n",
       "std          22.64603       0.095738       0.081709       0.173361   \n",
       "min           1.00000       0.500100       0.008600       0.300000   \n",
       "25%           1.00000       0.747400       0.093400       0.521900   \n",
       "50%           1.00000       0.830100       0.152600       0.674900   \n",
       "75%           2.00000       0.897300       0.221900       0.802200   \n",
       "max       12086.00000       0.990800       0.350000       0.982100   \n",
       "\n",
       "                year     colloquial  \n",
       "count  668534.000000  668534.000000  \n",
       "mean     2017.536327       0.383233  \n",
       "std         1.770882       0.486175  \n",
       "min      2015.000000       0.000000  \n",
       "25%      2016.000000       0.000000  \n",
       "50%      2018.000000       0.000000  \n",
       "75%      2019.000000       1.000000  \n",
       "max      2020.000000       1.000000  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f74439b",
   "metadata": {},
   "source": [
    "About 38.3% of quotes are qualified as colloquial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a806092e",
   "metadata": {},
   "source": [
    "### Most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78c4c18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>occurences</th>\n",
       "      <th>occurence_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>it's</td>\n",
       "      <td>117142</td>\n",
       "      <td>0.175222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>don't</td>\n",
       "      <td>64493</td>\n",
       "      <td>0.096469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>i'm</td>\n",
       "      <td>55166</td>\n",
       "      <td>0.082518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>that's</td>\n",
       "      <td>52490</td>\n",
       "      <td>0.078515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>we're</td>\n",
       "      <td>46661</td>\n",
       "      <td>0.069796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>he's</td>\n",
       "      <td>30909</td>\n",
       "      <td>0.046234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>there's</td>\n",
       "      <td>24987</td>\n",
       "      <td>0.037376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>we've</td>\n",
       "      <td>24858</td>\n",
       "      <td>0.037183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>didn't</td>\n",
       "      <td>24844</td>\n",
       "      <td>0.037162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>i've</td>\n",
       "      <td>23632</td>\n",
       "      <td>0.035349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>can't</td>\n",
       "      <td>22724</td>\n",
       "      <td>0.033991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>you're</td>\n",
       "      <td>20847</td>\n",
       "      <td>0.031183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>they're</td>\n",
       "      <td>20229</td>\n",
       "      <td>0.030259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>doesn't</td>\n",
       "      <td>14640</td>\n",
       "      <td>0.021899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>we'll</td>\n",
       "      <td>12153</td>\n",
       "      <td>0.018179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>wasn't</td>\n",
       "      <td>10342</td>\n",
       "      <td>0.015470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>what's</td>\n",
       "      <td>7530</td>\n",
       "      <td>0.011263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>i'll</td>\n",
       "      <td>7458</td>\n",
       "      <td>0.011156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>i'd</td>\n",
       "      <td>7266</td>\n",
       "      <td>0.010869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>won't</td>\n",
       "      <td>6885</td>\n",
       "      <td>0.010299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>haven't</td>\n",
       "      <td>6863</td>\n",
       "      <td>0.010266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>you've</td>\n",
       "      <td>6736</td>\n",
       "      <td>0.010076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>couldn't</td>\n",
       "      <td>6716</td>\n",
       "      <td>0.010046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>isn't</td>\n",
       "      <td>6159</td>\n",
       "      <td>0.009213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>they've</td>\n",
       "      <td>6075</td>\n",
       "      <td>0.009087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  occurences  occurence_fraction\n",
       "63        it's       117142            0.175222\n",
       "19       don't        64493            0.096469\n",
       "54         i'm        55166            0.082518\n",
       "102     that's        52490            0.078515\n",
       "129      we're        46661            0.069796\n",
       "42        he's        30909            0.046234\n",
       "107    there's        24987            0.037376\n",
       "130      we've        24858            0.037183\n",
       "17      didn't        24844            0.037162\n",
       "59        i've        23632            0.035349\n",
       "6        can't        22724            0.033991\n",
       "174     you're        20847            0.031183\n",
       "112    they're        20229            0.030259\n",
       "18     doesn't        14640            0.021899\n",
       "128      we'll        12153            0.018179\n",
       "125     wasn't        10342            0.015470\n",
       "136     what's         7530            0.011263\n",
       "53        i'll         7458            0.011156\n",
       "49         i'd         7266            0.010869\n",
       "159      won't         6885            0.010299\n",
       "38     haven't         6863            0.010266\n",
       "175     you've         6736            0.010076\n",
       "11    couldn't         6716            0.010046\n",
       "60       isn't         6159            0.009213\n",
       "113    they've         6075            0.009087"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dico[\"occurence_fraction\"]= dico[\"occurences\"]/df[\"colloquial\"].count()\n",
    "dico.sort_values(by='occurence_fraction', ascending=False)[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046758cd",
   "metadata": {},
   "source": [
    "## Classification using the reduced dictionary\n",
    "The dataset quotes are classified again using a dictionary from which the most common words have been removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28d2ac6",
   "metadata": {},
   "source": [
    "### Removal of word that appear in more than a certain fraction of words defined in the thresh variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65307066",
   "metadata": {},
   "outputs": [],
   "source": [
    "tresh= 0.02\n",
    "dico2= dico[dico[\"occurence_fraction\"]<tresh]\n",
    "dicolist2= dico2[\"word\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45edcd6",
   "metadata": {},
   "source": [
    "### Classifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6c2f478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a79c56931844ffbfd1adb18503fc14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/668534 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"colloquial\"]= df_tested_quotes.progress_apply(lambda x : isinside2(x.lower(),dicolist2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b612ac",
   "metadata": {},
   "source": [
    "### Quotes statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "00b4d058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numOccurrences</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>delta_p</th>\n",
       "      <th>year</th>\n",
       "      <th>colloquial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>668534.00000</td>\n",
       "      <td>668534.000000</td>\n",
       "      <td>668534.000000</td>\n",
       "      <td>668534.000000</td>\n",
       "      <td>668534.000000</td>\n",
       "      <td>668534.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.55898</td>\n",
       "      <td>0.818245</td>\n",
       "      <td>0.161096</td>\n",
       "      <td>0.657149</td>\n",
       "      <td>2017.536327</td>\n",
       "      <td>0.102488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22.64603</td>\n",
       "      <td>0.095738</td>\n",
       "      <td>0.081709</td>\n",
       "      <td>0.173361</td>\n",
       "      <td>1.770882</td>\n",
       "      <td>0.303290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.500100</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.747400</td>\n",
       "      <td>0.093400</td>\n",
       "      <td>0.521900</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.830100</td>\n",
       "      <td>0.152600</td>\n",
       "      <td>0.674900</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.00000</td>\n",
       "      <td>0.897300</td>\n",
       "      <td>0.221900</td>\n",
       "      <td>0.802200</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12086.00000</td>\n",
       "      <td>0.990800</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.982100</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       numOccurrences             p1             p2        delta_p  \\\n",
       "count    668534.00000  668534.000000  668534.000000  668534.000000   \n",
       "mean          3.55898       0.818245       0.161096       0.657149   \n",
       "std          22.64603       0.095738       0.081709       0.173361   \n",
       "min           1.00000       0.500100       0.008600       0.300000   \n",
       "25%           1.00000       0.747400       0.093400       0.521900   \n",
       "50%           1.00000       0.830100       0.152600       0.674900   \n",
       "75%           2.00000       0.897300       0.221900       0.802200   \n",
       "max       12086.00000       0.990800       0.350000       0.982100   \n",
       "\n",
       "                year     colloquial  \n",
       "count  668534.000000  668534.000000  \n",
       "mean     2017.536327       0.102488  \n",
       "std         1.770882       0.303290  \n",
       "min      2015.000000       0.000000  \n",
       "25%      2016.000000       0.000000  \n",
       "50%      2018.000000       0.000000  \n",
       "75%      2019.000000       0.000000  \n",
       "max      2020.000000       1.000000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c9f64a",
   "metadata": {},
   "source": [
    "We now have 10.2% of colloquial quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e59915b",
   "metadata": {},
   "source": [
    "## Quotes classification examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9f790de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 formal quotes sample : \n",
      "\n",
      "\n",
      "I can only talk from last year, but I think we had the feeling that we were like a top-two team and we maybe had the pressure in the semifinal. I think this group, and this year, is different. I think we can strike from behind and focus on being on the semifinal.\n",
      "\n",
      "\n",
      "For the most part, everything else at United is going really well. Operationally, United is running the best airline... that we ever run,\n",
      "\n",
      "\n",
      "It's temporary. Water is yet to recede in many places. As a result, less fish is being netted. Moreover, the ban on catching hilsa fish is another reason for the crisis.\n",
      "\n",
      "\n",
      "Do you have what it takes to finish?\n",
      "\n",
      "\n",
      "She is described as waifish -- that is, she was shorter than most models in the 90s -- but in reality, it's a small difference.\n",
      "5 colloquial quotes sample : \n",
      "\n",
      "\n",
      "And there's a big dish in the middle that my husband's mother couldn't bear to throw away. And that ended up in the window.\n",
      "\n",
      "\n",
      "You've got to be a winner and have all the right trajectory as a player and as a team to back that up,\n",
      "\n",
      "\n",
      "When I saw the photos when I was in Arizona, I was extremely concerned. Did you ever hang a flat-screen [ television ] on your wall, and your wife is telling you it's too big and you're arguing it's not too big, even though you know it's too big? That's how I thought I'd be, and I got here... It's perfect.\n",
      "\n",
      "\n",
      "I think we're gon na be there at the end of the year as well with the numbers to prove it. You've got front line guys, guys with experience, you've got young arms that are just pups but they're really really good and we're gon na use a lot of 'em. It's gon na make for a longer game but I want those guys to have as many opportunities when they get into postseason to have those extra three or four times.\n",
      "\n",
      "\n",
      "The big thing is -- when you're creating any team, you don't want to put too much pressure on anyone. There are six batsmen who've all got different styles etc etc and he's just one of six or seven. If you're going to do well in India, you have to get in and then go on. Kane has the advantage of having scored his first Test hundred in India on debut and he's a beautiful player of spin bowling. I'm sure he'll have a great tour and people will love watching him bat because people understand cricket in India and love watching good players.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "df_formal= df[df[\"colloquial\"]==0].reset_index()\n",
    "df_colloquial= df[df[\"colloquial\"]==1].reset_index()\n",
    "\n",
    "print(\"5 formal quotes sample : \")\n",
    "for i in random.sample(range(len(df_formal)), 5):\n",
    "    print(\"\\n\")\n",
    "    print(df_formal[\"quotation\"].loc[i])\n",
    "\n",
    "print(\"\\n5 colloquial quotes sample : \")\n",
    "for i in random.sample(range(len(df_colloquial)), 5):\n",
    "    print(\"\\n\")\n",
    "    print(df_colloquial[\"quotation\"].loc[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
