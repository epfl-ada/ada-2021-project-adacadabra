{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81209f7e",
   "metadata": {},
   "source": [
    "# Quotes classification\n",
    "\n",
    "In this notebook, we treat each quote of the corpus and assign them a score, or a binary variable determining if the quote is formal or informal according the dictionnary of informal formulation and slang vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9babeebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexb\\AppData\\Local\\Temp/ipykernel_26236/1470799504.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  tqdm_notebook().pandas()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "656e42a22e064ee48d0a7006828bb4e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#packages\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "tqdm_notebook().pandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56160801",
   "metadata": {},
   "source": [
    "### Comparison fonctions\n",
    "The following function are used to extract the quotes with word present in our dictionnary of slang/informal words. It consist simply to search for a specific string in the dico and updating the dict with the number of time the word had been found in the quotes. This value will be used latter in the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d95a56c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to check if strin is contained and update dico\n",
    "def isinside1(test_string,test_list):\n",
    "    global dico\n",
    "    res = [ele for ele in test_list if(ele in test_string)]\n",
    "    #print(res)\n",
    "    if res:\n",
    "        for ele in res:\n",
    "            i= test_list.index(ele)\n",
    "            dico[\"occurences\"].loc[i]= dico[\"occurences\"].loc[i]+1\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def isinside2(test_string,test_list):\n",
    "    if any(ext in test_string for ext in test_list):\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11d4c95",
   "metadata": {},
   "source": [
    "### The dictionnary\n",
    "The dictionnary is compiled in the notebook *dictionnary_Merging_Cleaning.ipynb* and his compiled with this 3 different sources:\n",
    "- [Urban Dictionnary](https://www.urbandictionary.com/define.php?term=Urban%20Dictionary)\n",
    "- [Informal English Vocabulary](https://www.englisch-hilfen.de/en/words/informal2.htm)\n",
    "- [A Dictionary of English Slang & Colloquialisms](http://www.peevish.co.uk/slang/english-slang/b.htm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c50ab2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>occurences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19773</th>\n",
       "      <td>shell out</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3015</th>\n",
       "      <td>jank</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>Wah</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12234</th>\n",
       "      <td>re</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19814</th>\n",
       "      <td>shit (somone)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19193</th>\n",
       "      <td>pillow-biter</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7054</th>\n",
       "      <td>BEDSHITTER</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5661</th>\n",
       "      <td>Uggdugg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10361</th>\n",
       "      <td>lesbians</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19418</th>\n",
       "      <td>purple-headed warrior</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        word  occurences\n",
       "19773              shell out           0\n",
       "3015                    jank           0\n",
       "1199                     Wah           0\n",
       "12234                     re           0\n",
       "19814          shit (somone)           0\n",
       "19193          pillow-biter            0\n",
       "7054              BEDSHITTER           0\n",
       "5661                 Uggdugg           0\n",
       "10361               lesbians           0\n",
       "19418  purple-headed warrior           0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get dico\n",
    "dico= pd.read_pickle(\"./Final_Dictionary.pkl\")\n",
    "dico[\"occurences\"]=0\n",
    "dico.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e43527",
   "metadata": {},
   "source": [
    "Adding one column on the expression/word length which could be useful for further statistics. It is also the time to check for any duplicates which should not be the case as the dico was cleaned in the *Dictionaries_Merging_Cleaning.ipynb* notebook but you can never be too careful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e5cb7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occurences</th>\n",
       "      <th>strlen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20989.0</td>\n",
       "      <td>20989.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.810520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.998863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       occurences        strlen\n",
       "count     20989.0  20989.000000\n",
       "mean          0.0      8.810520\n",
       "std           0.0      4.998863\n",
       "min           0.0      1.000000\n",
       "25%           0.0      6.000000\n",
       "50%           0.0      8.000000\n",
       "75%           0.0     11.000000\n",
       "max           0.0    143.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check strings lenths and describe dico\n",
    "dico[\"strlen\"]= dico[\"word\"].apply(lambda x : len(x))\n",
    "#make list out of dico\n",
    "dicolist= dico[\"word\"].unique().tolist()\n",
    "dico.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad56614",
   "metadata": {},
   "source": [
    "### Comparison between the dictionnary and the Quotebank sample\n",
    "Importation of a 600'000 cleaned sample extracted from the original Quotbank database. For the data wrangling process check the notebook *Data Wrangling Quotebank.ipynb* in the folder DATAWRANGLING of the git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "776c39c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALEX: C:/Users/alexb/Documents/Ecole/EPFL/MasterII/ADA/Sample_cleaned_1Mio.json.bz2\n",
    "#NICO: \"/Users/nicolasantacroce/Desktop/Desktop/EPFL/EPFL MA1/Applied Data Analysis/Sample.json.bz2\"\n",
    "#importing dataset sample\n",
    "df= pd.read_json(\"C:/Users/alexb/Documents/Ecole/EPFL/MasterII/ADA/Sample_cleaned_1Mio.json.bz2\",compression=\"bz2\",lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d294b87e",
   "metadata": {},
   "source": [
    "Separation of the quotes using the above described function. This is the most time consuming step (about 0.03 [s/quotes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58aa2524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a101a522f74107a35a05aed87a2ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/668534 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexb\\mambaforge\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "#separating quotes (really long so we try it on the first 10000)\n",
    "#df2= df.loc[0:70000]\n",
    "df2 = df\n",
    "df2[\"colloquial\"]= df2[\"quotation\"].progress_apply(lambda x : isinside1(x,dicolist))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34f6eb3",
   "metadata": {},
   "source": [
    "Sanity check, all fields are filled and we can see that 99.99% of the quotes are categorized as colloquial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2075013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numOccurrences</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>delta_p</th>\n",
       "      <th>year</th>\n",
       "      <th>colloquial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>668534.00000</td>\n",
       "      <td>668534.000000</td>\n",
       "      <td>668534.000000</td>\n",
       "      <td>668534.000000</td>\n",
       "      <td>668534.000000</td>\n",
       "      <td>668534.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.55898</td>\n",
       "      <td>0.818245</td>\n",
       "      <td>0.161096</td>\n",
       "      <td>0.657149</td>\n",
       "      <td>2017.536327</td>\n",
       "      <td>0.999957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22.64603</td>\n",
       "      <td>0.095738</td>\n",
       "      <td>0.081709</td>\n",
       "      <td>0.173361</td>\n",
       "      <td>1.770882</td>\n",
       "      <td>0.006586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.500100</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.747400</td>\n",
       "      <td>0.093400</td>\n",
       "      <td>0.521900</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.830100</td>\n",
       "      <td>0.152600</td>\n",
       "      <td>0.674900</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.00000</td>\n",
       "      <td>0.897300</td>\n",
       "      <td>0.221900</td>\n",
       "      <td>0.802200</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12086.00000</td>\n",
       "      <td>0.990800</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.982100</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       numOccurrences             p1             p2        delta_p  \\\n",
       "count    668534.00000  668534.000000  668534.000000  668534.000000   \n",
       "mean          3.55898       0.818245       0.161096       0.657149   \n",
       "std          22.64603       0.095738       0.081709       0.173361   \n",
       "min           1.00000       0.500100       0.008600       0.300000   \n",
       "25%           1.00000       0.747400       0.093400       0.521900   \n",
       "50%           1.00000       0.830100       0.152600       0.674900   \n",
       "75%           2.00000       0.897300       0.221900       0.802200   \n",
       "max       12086.00000       0.990800       0.350000       0.982100   \n",
       "\n",
       "                year     colloquial  \n",
       "count  668534.000000  668534.000000  \n",
       "mean     2017.536327       0.999957  \n",
       "std         1.770882       0.006586  \n",
       "min      2015.000000       0.000000  \n",
       "25%      2016.000000       1.000000  \n",
       "50%      2018.000000       1.000000  \n",
       "75%      2019.000000       1.000000  \n",
       "max      2020.000000       1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2cd64b",
   "metadata": {},
   "source": [
    "The fact that all quotes are categorized as colloquial is not surprising given the size of the dictionary used (>20'000 entries). Some common words are included, but not all of them are categorized as colloquial. This is why we will focus on the less frequently occurring terms, which will define a clearer distinction between formal and informal language. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e577fc",
   "metadata": {},
   "source": [
    "### Dictionnary reduction\n",
    "The threshold was set at 0.001. This means that the expression must not appear in more than one quote out of a thousand to remain in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "217154c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occurences</th>\n",
       "      <th>strlen</th>\n",
       "      <th>occurence_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20989.000000</td>\n",
       "      <td>20989.000000</td>\n",
       "      <td>20989.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>816.276716</td>\n",
       "      <td>8.810520</td>\n",
       "      <td>0.001221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12365.917242</td>\n",
       "      <td>4.998863</td>\n",
       "      <td>0.018497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>639634.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>0.956771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          occurences        strlen  occurence_fraction\n",
       "count   20989.000000  20989.000000        20989.000000\n",
       "mean      816.276716      8.810520            0.001221\n",
       "std     12365.917242      4.998863            0.018497\n",
       "min         0.000000      1.000000            0.000000\n",
       "25%         0.000000      6.000000            0.000000\n",
       "50%         0.000000      8.000000            0.000000\n",
       "75%         2.000000     11.000000            0.000003\n",
       "max    639634.000000    143.000000            0.956771"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing words present in more than 0.1% of quotes\n",
    "tresh= 0.001\n",
    "dico[\"occurence_fraction\"]= dico[\"occurences\"]/df2[\"colloquial\"].count()\n",
    "dico.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66e6288c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occurences</th>\n",
       "      <th>strlen</th>\n",
       "      <th>occurence_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20116.000000</td>\n",
       "      <td>20116.000000</td>\n",
       "      <td>20116.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16.672947</td>\n",
       "      <td>9.011981</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>68.375757</td>\n",
       "      <td>4.997072</td>\n",
       "      <td>0.000102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>666.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>0.000996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         occurences        strlen  occurence_fraction\n",
       "count  20116.000000  20116.000000        20116.000000\n",
       "mean      16.672947      9.011981            0.000025\n",
       "std       68.375757      4.997072            0.000102\n",
       "min        0.000000      1.000000            0.000000\n",
       "25%        0.000000      6.000000            0.000000\n",
       "50%        0.000000      8.000000            0.000000\n",
       "75%        1.000000     11.000000            0.000001\n",
       "max      666.000000    143.000000            0.000996"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating new dictionary without most occuring words\n",
    "dico2= dico[dico[\"occurence_fraction\"]<tresh]\n",
    "dicolist2= dico2[\"word\"].unique().tolist()\n",
    "dico2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09dc5a7",
   "metadata": {},
   "source": [
    "We use the same functions as before to search in the quotes but this time with a reduced dictionnary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "093eccde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "219dfb2bf187495698b4dd1702f87f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/668534 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#re-evaluating quotes with reduced dictionary\n",
    "df2[\"colloquial\"]= df2[\"quotation\"].progress_apply(lambda x : isinside2(x,dicolist2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc299d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>qids</th>\n",
       "      <th>date</th>\n",
       "      <th>numOccurrences</th>\n",
       "      <th>probas</th>\n",
       "      <th>urls</th>\n",
       "      <th>phase</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>delta_p</th>\n",
       "      <th>year</th>\n",
       "      <th>colloquial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-11-11-109291</td>\n",
       "      <td>They'll call me lots of different things. Libe...</td>\n",
       "      <td>Chris Christie</td>\n",
       "      <td>[Q63879]</td>\n",
       "      <td>2015-11-11 00:55:12</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Chris Christie, 0.7395], [Bobby Jindal, 0.15...</td>\n",
       "      <td>[http://thehill.com/blogs/ballot-box/259760-ch...</td>\n",
       "      <td>E</td>\n",
       "      <td>0.7395</td>\n",
       "      <td>0.1505</td>\n",
       "      <td>0.5890</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-09-11-070666</td>\n",
       "      <td>It's kind of the same way it's been with the R...</td>\n",
       "      <td>Niklas Kronwall</td>\n",
       "      <td>[Q722939]</td>\n",
       "      <td>2015-09-11 19:54:00</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Niklas Kronwall, 0.7119], [None, 0.2067], [H...</td>\n",
       "      <td>[http://redwings.nhl.com/club/news.htm?id=7787...</td>\n",
       "      <td>E</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2067</td>\n",
       "      <td>0.5052</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-11-09-033345</td>\n",
       "      <td>I had a chuckle: They were showing a video of ...</td>\n",
       "      <td>Kris Draper</td>\n",
       "      <td>[Q948695]</td>\n",
       "      <td>2015-11-09 00:57:45</td>\n",
       "      <td>3</td>\n",
       "      <td>[[Kris Draper, 0.8782], [None, 0.1043], [Serge...</td>\n",
       "      <td>[http://ca.rd.yahoo.com/sports/rss/nfl/SIG=13u...</td>\n",
       "      <td>E</td>\n",
       "      <td>0.8782</td>\n",
       "      <td>0.1043</td>\n",
       "      <td>0.7739</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-09-05-038628</td>\n",
       "      <td>New Zealand will go in with a lot of confidenc...</td>\n",
       "      <td>John Eales</td>\n",
       "      <td>[Q926351]</td>\n",
       "      <td>2015-09-05 02:40:10</td>\n",
       "      <td>3</td>\n",
       "      <td>[[John Eales, 0.7896], [None, 0.2006], [Toutai...</td>\n",
       "      <td>[http://www.stuff.co.nz/sport/rugby/all-blacks...</td>\n",
       "      <td>E</td>\n",
       "      <td>0.7896</td>\n",
       "      <td>0.2006</td>\n",
       "      <td>0.5890</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-11-042325</td>\n",
       "      <td>In his suicide note he even made a joke thanki...</td>\n",
       "      <td>Pat Buckley</td>\n",
       "      <td>[Q19956564, Q23006312, Q7143252, Q7143253]</td>\n",
       "      <td>2015-02-11 09:59:09</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Pat Buckley, 0.8816], [None, 0.1184]]</td>\n",
       "      <td>[http://independent.ie/life/health-wellbeing/m...</td>\n",
       "      <td>E</td>\n",
       "      <td>0.8816</td>\n",
       "      <td>0.1184</td>\n",
       "      <td>0.7632</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             quoteID                                          quotation  \\\n",
       "0  2015-11-11-109291  They'll call me lots of different things. Libe...   \n",
       "1  2015-09-11-070666  It's kind of the same way it's been with the R...   \n",
       "2  2015-11-09-033345  I had a chuckle: They were showing a video of ...   \n",
       "3  2015-09-05-038628  New Zealand will go in with a lot of confidenc...   \n",
       "4  2015-02-11-042325  In his suicide note he even made a joke thanki...   \n",
       "\n",
       "           speaker                                        qids  \\\n",
       "0   Chris Christie                                    [Q63879]   \n",
       "1  Niklas Kronwall                                   [Q722939]   \n",
       "2      Kris Draper                                   [Q948695]   \n",
       "3       John Eales                                   [Q926351]   \n",
       "4      Pat Buckley  [Q19956564, Q23006312, Q7143252, Q7143253]   \n",
       "\n",
       "                 date  numOccurrences  \\\n",
       "0 2015-11-11 00:55:12               1   \n",
       "1 2015-09-11 19:54:00               1   \n",
       "2 2015-11-09 00:57:45               3   \n",
       "3 2015-09-05 02:40:10               3   \n",
       "4 2015-02-11 09:59:09               1   \n",
       "\n",
       "                                              probas  \\\n",
       "0  [[Chris Christie, 0.7395], [Bobby Jindal, 0.15...   \n",
       "1  [[Niklas Kronwall, 0.7119], [None, 0.2067], [H...   \n",
       "2  [[Kris Draper, 0.8782], [None, 0.1043], [Serge...   \n",
       "3  [[John Eales, 0.7896], [None, 0.2006], [Toutai...   \n",
       "4            [[Pat Buckley, 0.8816], [None, 0.1184]]   \n",
       "\n",
       "                                                urls phase      p1      p2  \\\n",
       "0  [http://thehill.com/blogs/ballot-box/259760-ch...     E  0.7395  0.1505   \n",
       "1  [http://redwings.nhl.com/club/news.htm?id=7787...     E  0.7119  0.2067   \n",
       "2  [http://ca.rd.yahoo.com/sports/rss/nfl/SIG=13u...     E  0.8782  0.1043   \n",
       "3  [http://www.stuff.co.nz/sport/rugby/all-blacks...     E  0.7896  0.2006   \n",
       "4  [http://independent.ie/life/health-wellbeing/m...     E  0.8816  0.1184   \n",
       "\n",
       "   delta_p  year  colloquial  \n",
       "0   0.5890  2015           0  \n",
       "1   0.5052  2015           0  \n",
       "2   0.7739  2015           1  \n",
       "3   0.5890  2015           0  \n",
       "4   0.7632  2015           1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8518614e",
   "metadata": {},
   "source": [
    "Now we can display the dictionary with the updated occurence_fraction columns. It allows to have a first overview on the type of words present in the sample without being too frequent (in this case 1 quote on 1000). Of course we can see that single words are in the majority but we also find some expressions built in several words in the top of this ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "feaeffcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>occurences</th>\n",
       "      <th>strlen</th>\n",
       "      <th>occurence_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14693</th>\n",
       "      <td>Stu</td>\n",
       "      <td>666</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15642</th>\n",
       "      <td>email</td>\n",
       "      <td>666</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <td>htf</td>\n",
       "      <td>666</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>dish</td>\n",
       "      <td>664</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>warn</td>\n",
       "      <td>663</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20299</th>\n",
       "      <td>suit</td>\n",
       "      <td>662</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3810</th>\n",
       "      <td>boat</td>\n",
       "      <td>661</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19591</th>\n",
       "      <td>ruck</td>\n",
       "      <td>660</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>dip</td>\n",
       "      <td>660</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18698</th>\n",
       "      <td>mits</td>\n",
       "      <td>659</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7521</th>\n",
       "      <td>shak</td>\n",
       "      <td>656</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2287</th>\n",
       "      <td>bass</td>\n",
       "      <td>651</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5312</th>\n",
       "      <td>relax</td>\n",
       "      <td>649</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5366</th>\n",
       "      <td>Time</td>\n",
       "      <td>646</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5147</th>\n",
       "      <td>ignit</td>\n",
       "      <td>645</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>sweet</td>\n",
       "      <td>643</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2627</th>\n",
       "      <td>reject</td>\n",
       "      <td>642</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5064</th>\n",
       "      <td>hick</td>\n",
       "      <td>641</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4226</th>\n",
       "      <td>bell</td>\n",
       "      <td>635</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2619</th>\n",
       "      <td>internet</td>\n",
       "      <td>631</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19610</th>\n",
       "      <td>rush</td>\n",
       "      <td>629</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20458</th>\n",
       "      <td>tight</td>\n",
       "      <td>628</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12997</th>\n",
       "      <td>code</td>\n",
       "      <td>627</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>dry</td>\n",
       "      <td>627</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15019</th>\n",
       "      <td>Medic</td>\n",
       "      <td>625</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8984</th>\n",
       "      <td>the earl</td>\n",
       "      <td>624</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>grass</td>\n",
       "      <td>624</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>punish</td>\n",
       "      <td>622</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>owned</td>\n",
       "      <td>621</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19839</th>\n",
       "      <td>shop</td>\n",
       "      <td>620</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16844</th>\n",
       "      <td>busy</td>\n",
       "      <td>620</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13412</th>\n",
       "      <td>holes</td>\n",
       "      <td>616</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13273</th>\n",
       "      <td>nose</td>\n",
       "      <td>616</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7578</th>\n",
       "      <td>gib</td>\n",
       "      <td>616</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20720</th>\n",
       "      <td>village</td>\n",
       "      <td>615</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10538</th>\n",
       "      <td>oine</td>\n",
       "      <td>615</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>rox</td>\n",
       "      <td>612</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20767</th>\n",
       "      <td>waste</td>\n",
       "      <td>609</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20585</th>\n",
       "      <td>trip</td>\n",
       "      <td>608</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5872</th>\n",
       "      <td>bbl</td>\n",
       "      <td>607</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19091</th>\n",
       "      <td>pan</td>\n",
       "      <td>607</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18925</th>\n",
       "      <td>nous</td>\n",
       "      <td>606</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19679</th>\n",
       "      <td>scop</td>\n",
       "      <td>606</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5328</th>\n",
       "      <td>rude</td>\n",
       "      <td>606</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16881</th>\n",
       "      <td>camp</td>\n",
       "      <td>602</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7559</th>\n",
       "      <td>on one</td>\n",
       "      <td>602</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14973</th>\n",
       "      <td>Roc</td>\n",
       "      <td>601</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15557</th>\n",
       "      <td>nial</td>\n",
       "      <td>597</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>semen</td>\n",
       "      <td>597</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20072</th>\n",
       "      <td>SP</td>\n",
       "      <td>597</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5012</th>\n",
       "      <td>96</td>\n",
       "      <td>594</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>snow</td>\n",
       "      <td>594</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6669</th>\n",
       "      <td>laid</td>\n",
       "      <td>593</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7251</th>\n",
       "      <td>strum</td>\n",
       "      <td>592</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3085</th>\n",
       "      <td>fruit</td>\n",
       "      <td>592</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2960</th>\n",
       "      <td>captain</td>\n",
       "      <td>590</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>be out</td>\n",
       "      <td>588</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19201</th>\n",
       "      <td>pip</td>\n",
       "      <td>588</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>courts</td>\n",
       "      <td>587</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>no way</td>\n",
       "      <td>586</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  occurences  strlen  occurence_fraction\n",
       "14693       Stu         666       3            0.000996\n",
       "15642     email         666       5            0.000996\n",
       "2975        htf         666       3            0.000996\n",
       "1027       dish         664       4            0.000993\n",
       "57         warn         663       4            0.000992\n",
       "20299     suit          662       5            0.000990\n",
       "3810       boat         661       4            0.000989\n",
       "19591     ruck          660       5            0.000987\n",
       "2133        dip         660       3            0.000987\n",
       "18698      mits         659       4            0.000986\n",
       "7521       shak         656       4            0.000981\n",
       "2287       bass         651       4            0.000974\n",
       "5312      relax         649       5            0.000971\n",
       "5366       Time         646       4            0.000966\n",
       "5147      ignit         645       5            0.000965\n",
       "54        sweet         643       5            0.000962\n",
       "2627     reject         642       6            0.000960\n",
       "5064       hick         641       4            0.000959\n",
       "4226       bell         635       4            0.000950\n",
       "2619   internet         631       8            0.000944\n",
       "19610     rush          629       5            0.000941\n",
       "20458    tight          628       6            0.000939\n",
       "12997      code         627       4            0.000938\n",
       "1829        dry         627       3            0.000938\n",
       "15019     Medic         625       5            0.000935\n",
       "8984   the earl         624       8            0.000933\n",
       "947       grass         624       5            0.000933\n",
       "5724     punish         622       6            0.000930\n",
       "1362      owned         621       5            0.000929\n",
       "19839     shop          620       5            0.000927\n",
       "16844     busy          620       5            0.000927\n",
       "13412     holes         616       5            0.000921\n",
       "13273      nose         616       4            0.000921\n",
       "7578        gib         616       3            0.000921\n",
       "20720   village         615       7            0.000920\n",
       "10538      oine         615       4            0.000920\n",
       "2591        rox         612       3            0.000915\n",
       "20767    waste          609       6            0.000911\n",
       "20585     trip          608       5            0.000909\n",
       "5872        bbl         607       3            0.000908\n",
       "19091      pan          607       4            0.000908\n",
       "18925      nous         606       4            0.000906\n",
       "19679      scop         606       4            0.000906\n",
       "5328       rude         606       4            0.000906\n",
       "16881     camp          602       5            0.000900\n",
       "7559     on one         602       6            0.000900\n",
       "14973       Roc         601       3            0.000899\n",
       "15557      nial         597       4            0.000893\n",
       "2745      semen         597       5            0.000893\n",
       "20072        SP         597       2            0.000893\n",
       "5012         96         594       2            0.000889\n",
       "549        snow         594       4            0.000889\n",
       "6669       laid         593       4            0.000887\n",
       "7251      strum         592       5            0.000886\n",
       "3085      fruit         592       5            0.000886\n",
       "2960    captain         590       7            0.000883\n",
       "1412     be out         588       6            0.000880\n",
       "19201       pip         588       3            0.000880\n",
       "359      courts         587       6            0.000878\n",
       "28       no way         586       6            0.000877"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dico2 = dico2.sort_values(by=['occurence_fraction'], ascending=False)\n",
    "dico2.head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f37a352",
   "metadata": {},
   "source": [
    "Finally we can export de data to proceed at the next steps of the project that consist on:\n",
    "\n",
    "- try do learn more about the data we have with the below sample\n",
    "- prepare adequate notebooks to underline the insides of the data once we run the whole process with the entire data frame\n",
    "- get more hints about the story we could tell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1410a4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compression in bz2 format\n",
    "df2.to_json(f\"C:/Users/alexb/Documents/Ecole/EPFL/MasterII/ADA/Sample_classified_1Mio_v1.json.bz2\",compression=\"bz2\",lines=True,orient=\"records\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
