{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is dedicated to the retrieve of the speakers metadata. First, it uses the parquet file that was provided to retrieve extra-information (occupation, date of birth, gender, religion) on speakers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parquet file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas requires pyarrow to read parquet files, which can be installed using conda install pyarrow -c conda-forge.\n",
    "You can load this file as a pandas dataframe using df = pd.read_parquet(<path_to_file>)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Schema of parquet file : \n",
    "    \n",
    "    Schema:\n",
    " |-- aliases: array (nullable = true)\n",
    " |    |-- element: string (containsNull = true)\n",
    " |-- date_of_birth: array (nullable = true)\n",
    " |    |-- element: string (containsNull = true)\n",
    " |-- nationality: array (nullable = true)\n",
    " |    |-- element: string (containsNull = true)\n",
    " |-- gender: array (nullable = true)\n",
    " |    |-- element: string (containsNull = true)\n",
    " |-- lastrevid: long (nullable = true)\n",
    " |-- ethnic_group: array (nullable = true)\n",
    " |    |-- element: string (containsNull = true)\n",
    " |-- US_congress_bio_ID: string (nullable = true)\n",
    " |-- occupation: array (nullable = true)\n",
    " |    |-- element: string (containsNull = true)\n",
    " |-- party: array (nullable = true)\n",
    " |    |-- element: string (containsNull = true)\n",
    " |-- academic_degree: array (nullable = true)\n",
    " |    |-- element: string (containsNull = true)\n",
    " |-- id: string (nullable = true)\n",
    " |-- label: string (nullable = true)\n",
    " |-- candidacy: array (nullable = true)\n",
    " |    |-- element: string (containsNull = true)\n",
    " |-- type: string (nullable = true)\n",
    " |-- religion: array (nullable = true)\n",
    " |    |-- element: string (containsNull = true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required modules\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small adjustments to default style of plots, making sure it's readable and colorblind-friendly everywhere\n",
    "plt.style.use('seaborn-colorblind')\n",
    "plt.rcParams.update({'font.size' : 12.5,\n",
    "                     'figure.figsize':(10,7)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowMemoryError",
     "evalue": "malloc of size 1073741824 failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArrowMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9616/2327828956.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../ADA_project_data/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'speaker_attributes.parquet'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m     \u001b[0mimpl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 495\u001b[1;33m     return impl.read(\n\u001b[0m\u001b[0;32m    496\u001b[0m         \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    237\u001b[0m         )\n\u001b[0;32m    238\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m             result = self.api.parquet.read_table(\n\u001b[0m\u001b[0;32m    240\u001b[0m                 \u001b[0mpath_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             ).to_pandas(**to_pandas_kwargs)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\pyarrow\\array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib._PandasConvertible.to_pandas\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\pyarrow\\table.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.Table._to_pandas\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\pyarrow\\pandas_compat.py\u001b[0m in \u001b[0;36mtable_to_blockmanager\u001b[1;34m(options, table, categories, ignore_metadata, types_mapper)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[0m_check_data_column_metadata_consistency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_columns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m     \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deserialize_column_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_indexes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m     \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_table_to_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mext_columns_dtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m     \u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\pyarrow\\pandas_compat.py\u001b[0m in \u001b[0;36m_table_to_blocks\u001b[1;34m(options, block_table, categories, extension_columns)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;31m# Convert an arrow table to Block from the internal pandas API\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m     \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblock_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1128\u001b[1;33m     result = pa.lib.table_to_blocks(options, block_table, categories,\n\u001b[0m\u001b[0;32m   1129\u001b[0m                                     list(extension_columns.keys()))\n\u001b[0;32m   1130\u001b[0m     return [_reconstruct_block(item, columns, extension_columns)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\pyarrow\\table.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.table_to_blocks\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\pyarrow\\error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowMemoryError\u001b[0m: malloc of size 1073741824 failed"
     ]
    }
   ],
   "source": [
    "path = '../ADA_project_data/'\n",
    "\n",
    "df = pd.read_parquet(path+'speaker_attributes.parquet')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label']=='Donald Trump']\n",
    "df.index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the sample to join metadata with quotations : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>qids</th>\n",
       "      <th>date</th>\n",
       "      <th>numOccurrences</th>\n",
       "      <th>probas</th>\n",
       "      <th>urls</th>\n",
       "      <th>phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-11-11-109291</td>\n",
       "      <td>They'll call me lots of different things. Libe...</td>\n",
       "      <td>Chris Christie</td>\n",
       "      <td>[Q63879]</td>\n",
       "      <td>2015-11-11 00:55:12</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Chris Christie, 0.7395], [Bobby Jindal, 0.15...</td>\n",
       "      <td>[http://thehill.com/blogs/ballot-box/259760-ch...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-11-04-105046</td>\n",
       "      <td>The choices are not that easy,</td>\n",
       "      <td>Dr. John</td>\n",
       "      <td>[Q511074, Q54593093]</td>\n",
       "      <td>2015-11-04 18:13:06</td>\n",
       "      <td>2</td>\n",
       "      <td>[[Dr. John, 0.5531], [None, 0.4469]]</td>\n",
       "      <td>[http://delawareonline.com/story/news/health/2...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-09-11-070666</td>\n",
       "      <td>It's kind of the same way it's been with the R...</td>\n",
       "      <td>Niklas Kronwall</td>\n",
       "      <td>[Q722939]</td>\n",
       "      <td>2015-09-11 19:54:00</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Niklas Kronwall, 0.7119], [None, 0.2067], [H...</td>\n",
       "      <td>[http://redwings.nhl.com/club/news.htm?id=7787...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-12-082489</td>\n",
       "      <td>We're now going back to the frozen tundra, and...</td>\n",
       "      <td>Frances McDormand</td>\n",
       "      <td>[Q204299]</td>\n",
       "      <td>2015-01-12 01:40:00</td>\n",
       "      <td>3</td>\n",
       "      <td>[[Frances McDormand, 0.484], [None, 0.4495], [...</td>\n",
       "      <td>[http://feeds.people.com/~r/people/headlines/~...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-09-033345</td>\n",
       "      <td>I had a chuckle: They were showing a video of ...</td>\n",
       "      <td>Kris Draper</td>\n",
       "      <td>[Q948695]</td>\n",
       "      <td>2015-11-09 00:57:45</td>\n",
       "      <td>3</td>\n",
       "      <td>[[Kris Draper, 0.8782], [None, 0.1043], [Serge...</td>\n",
       "      <td>[http://ca.rd.yahoo.com/sports/rss/nfl/SIG=13u...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             quoteID                                          quotation  \\\n",
       "0  2015-11-11-109291  They'll call me lots of different things. Libe...   \n",
       "1  2015-11-04-105046                     The choices are not that easy,   \n",
       "2  2015-09-11-070666  It's kind of the same way it's been with the R...   \n",
       "3  2015-01-12-082489  We're now going back to the frozen tundra, and...   \n",
       "4  2015-11-09-033345  I had a chuckle: They were showing a video of ...   \n",
       "\n",
       "             speaker                  qids                date  \\\n",
       "0     Chris Christie              [Q63879] 2015-11-11 00:55:12   \n",
       "1           Dr. John  [Q511074, Q54593093] 2015-11-04 18:13:06   \n",
       "2    Niklas Kronwall             [Q722939] 2015-09-11 19:54:00   \n",
       "3  Frances McDormand             [Q204299] 2015-01-12 01:40:00   \n",
       "4        Kris Draper             [Q948695] 2015-11-09 00:57:45   \n",
       "\n",
       "   numOccurrences                                             probas  \\\n",
       "0               1  [[Chris Christie, 0.7395], [Bobby Jindal, 0.15...   \n",
       "1               2               [[Dr. John, 0.5531], [None, 0.4469]]   \n",
       "2               1  [[Niklas Kronwall, 0.7119], [None, 0.2067], [H...   \n",
       "3               3  [[Frances McDormand, 0.484], [None, 0.4495], [...   \n",
       "4               3  [[Kris Draper, 0.8782], [None, 0.1043], [Serge...   \n",
       "\n",
       "                                                urls phase  \n",
       "0  [http://thehill.com/blogs/ballot-box/259760-ch...     E  \n",
       "1  [http://delawareonline.com/story/news/health/2...     E  \n",
       "2  [http://redwings.nhl.com/club/news.htm?id=7787...     E  \n",
       "3  [http://feeds.people.com/~r/people/headlines/~...     E  \n",
       "4  [http://ca.rd.yahoo.com/sports/rss/nfl/SIG=13u...     E  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the dataset sample\n",
    "path = '../ADA_project_data/'\n",
    "raw_data = pd.read_json(path+'Sample.json.bz2',compression = 'bz2',lines = True)\n",
    "\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5655703"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join data with metadata :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aliases</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>nationality</th>\n",
       "      <th>gender</th>\n",
       "      <th>lastrevid</th>\n",
       "      <th>ethnic_group</th>\n",
       "      <th>US_congress_bio_ID</th>\n",
       "      <th>occupation</th>\n",
       "      <th>party</th>\n",
       "      <th>academic_degree</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>candidacy</th>\n",
       "      <th>type</th>\n",
       "      <th>religion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4937327</th>\n",
       "      <td>[Donald L. Trump, Donald Lynn Trump, Skip Trum...</td>\n",
       "      <td>[+1945-07-31T00:00:00Z, +1945-00-00T00:00:00Z]</td>\n",
       "      <td>[Q30]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>1392088288</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q39631, Q16062369]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q913404]</td>\n",
       "      <td>Q27947481</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>None</td>\n",
       "      <td>item</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   aliases  \\\n",
       "4937327  [Donald L. Trump, Donald Lynn Trump, Skip Trum...   \n",
       "\n",
       "                                          date_of_birth nationality  \\\n",
       "4937327  [+1945-07-31T00:00:00Z, +1945-00-00T00:00:00Z]       [Q30]   \n",
       "\n",
       "             gender   lastrevid ethnic_group US_congress_bio_ID  \\\n",
       "4937327  [Q6581097]  1392088288         None               None   \n",
       "\n",
       "                  occupation party academic_degree         id         label  \\\n",
       "4937327  [Q39631, Q16062369]  None       [Q913404]  Q27947481  Donald Trump   \n",
       "\n",
       "        candidacy  type religion  \n",
       "4937327      None  item     None  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trump = raw_data[raw_data['speaker']=='Donald Trump']\n",
    "df_trump.sample(50)\n",
    "\n",
    "\n",
    "df[df['label']==df_trump['speaker'].iloc[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aditionnal metadata from Wikidata "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script to retrieve metedata from Quotebank entries : "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "Execute this script as: \n",
    "python query_wikidata_dump.py --input <path-to-wikidata-json-dump> --output <path-to-output-json-file>\n",
    "'''\n",
    "\n",
    "import json\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from argparse import ArgumentParser\n",
    "import gzip\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"--input\", required=True)\n",
    "parser.add_argument(\"--output\", required=True)\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Usage:\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Do not enforce encoding here since the input encoding is correct\n",
    "    with open(args.output, \"w\") as output_file:\n",
    "        with gzip.open(args.input, 'rb') as s_file:\n",
    "            for instance in s_file:\n",
    "                instance = instance.decode('utf-8')\n",
    "                instance = instance[:-2]\n",
    "                if len(instance)==0:\n",
    "                    continue\n",
    "                s = json.loads(instance.strip(\"\\n\"))\n",
    "\n",
    "                if s.get(\"labels\", {}).get(\"en\") is not None:\n",
    "                    s[\"label\"] = s[\"labels\"][\"en\"][\"value\"]\n",
    "                if s.get(\"labels\") is not None:\n",
    "                    del s[\"labels\"]\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                # Occupation\n",
    "                if len(s.get(\"claims\", {}).get(\"P106\", [])) > 0:\n",
    "                    tmp = []\n",
    "                    for v in s[\"claims\"][\"P106\"]:\n",
    "                        # id: \"Q123\", \"numeric-id\": 123\n",
    "                        if (\n",
    "                            v[\"mainsnak\"].get(\"datavalue\", {}).get(\"value\", {}).get(\"id\")\n",
    "                            is not None\n",
    "                        ):\n",
    "                            tmp.append(v[\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"])\n",
    "                    if len(tmp) > 0:\n",
    "                        s[\"occupation\"] = tmp\n",
    "\n",
    "                # Gender\n",
    "                if len(s.get(\"claims\", {}).get(\"P21\", [])) > 0:\n",
    "                    tmp = []\n",
    "                    for v in s[\"claims\"][\"P21\"]:\n",
    "                        # id: \"Q123\", \"numeric-id\": 123\n",
    "                        if (\n",
    "                            v[\"mainsnak\"].get(\"datavalue\", {}).get(\"value\", {}).get(\"id\")\n",
    "                            is not None\n",
    "                        ):\n",
    "                            tmp.append(v[\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"])\n",
    "                    if len(tmp) > 0:\n",
    "                        s[\"gender\"] = tmp\n",
    "\n",
    "                # Country of citizenship\n",
    "                if len(s.get(\"claims\", {}).get(\"P27\", [])) > 0:\n",
    "                    tmp = []\n",
    "                    for v in s[\"claims\"][\"P27\"]:\n",
    "                        # id: \"Q123\", \"numeric-id\": 123\n",
    "                        if (\n",
    "                            v[\"mainsnak\"].get(\"datavalue\", {}).get(\"value\", {}).get(\"id\")\n",
    "                            is not None\n",
    "                        ):\n",
    "                            tmp.append(v[\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"])\n",
    "                    if len(tmp) > 0:\n",
    "                        s[\"nationality\"] = tmp\n",
    "\n",
    "                # Position Held\n",
    "                if len(s.get(\"claims\", {}).get(\"P39\", [])) > 0:\n",
    "                    tmp = []\n",
    "                    for v in s[\"claims\"][\"P39\"]:\n",
    "                        # id: \"Q123\", \"numeric-id\": 123\n",
    "                        if (\n",
    "                            v[\"mainsnak\"].get(\"datavalue\", {}).get(\"value\", {}).get(\"id\")\n",
    "                            is not None\n",
    "                        ):\n",
    "                            tmp.append(v[\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"])\n",
    "                    if len(tmp) > 0:\n",
    "                        s[\"positions_held\"] = tmp\n",
    "\n",
    "                # Date of Birth\n",
    "                if len(s.get(\"claims\", {}).get(\"P569\", [])) > 0:\n",
    "                    tmp = []\n",
    "                    for v in s[\"claims\"][\"P569\"]:\n",
    "                        if (\n",
    "                            v[\"mainsnak\"].get(\"datavalue\", {}).get(\"value\", {}).get(\"time\")\n",
    "                            is not None\n",
    "                        ):\n",
    "                            tmp.append(v[\"mainsnak\"][\"datavalue\"][\"value\"][\"time\"])\n",
    "                    if len(tmp) > 0:\n",
    "                        s[\"date_of_birth\"] = tmp\n",
    "\n",
    "                # Academic Degree\n",
    "                if len(s.get(\"claims\", {}).get(\"P512\", [])) > 0:\n",
    "                    tmp = []\n",
    "                    for v in s[\"claims\"][\"P512\"]:\n",
    "                        if (\n",
    "                            v[\"mainsnak\"].get(\"datavalue\", {}).get(\"value\", {}).get(\"id\")\n",
    "                            is not None\n",
    "                        ):\n",
    "                            tmp.append(v[\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"])\n",
    "                    if len(tmp) > 0:\n",
    "                        s[\"academic_degree\"] = tmp\n",
    "\n",
    "                # Member of Political Party\n",
    "                if len(s.get(\"claims\", {}).get(\"P102\", [])) > 0:\n",
    "                    tmp = []\n",
    "                    for v in s[\"claims\"][\"P102\"]:\n",
    "                        if (\n",
    "                            v[\"mainsnak\"].get(\"datavalue\", {}).get(\"value\", {}).get(\"id\")\n",
    "                            is not None\n",
    "                        ):\n",
    "                            tmp.append(v[\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"])\n",
    "                    if len(tmp) > 0:\n",
    "                        s[\"party\"] = tmp\n",
    "\n",
    "                # Candidacy in election\n",
    "                if len(s.get(\"claims\", {}).get(\"P3602\", [])) > 0:\n",
    "                    tmp = []\n",
    "                    for v in s[\"claims\"][\"P3602\"]:\n",
    "                        if (\n",
    "                            v[\"mainsnak\"].get(\"datavalue\", {}).get(\"value\", {}).get(\"id\")\n",
    "                            is not None\n",
    "                        ):\n",
    "                            tmp.append(v[\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"])\n",
    "                    if len(tmp) > 0:\n",
    "                        s[\"candidacy\"] = tmp\n",
    "\n",
    "                # US Congress Bio ID\n",
    "                # Get more information on the politicians based on the ID here: https://bioguide.congress.gov\n",
    "                if len(s.get(\"claims\", {}).get(\"P1157\", [])) > 0:\n",
    "                    tmp = None\n",
    "                    for v in s[\"claims\"][\"P1157\"]:\n",
    "                        if (\n",
    "                            v[\"mainsnak\"].get(\"datavalue\", {}).get(\"value\")\n",
    "                            is not None\n",
    "                        ):\n",
    "                            tmp = v[\"mainsnak\"][\"datavalue\"][\"value\"]\n",
    "                            break\n",
    "                    if tmp is not None:\n",
    "                        s[\"US_congress_bio_ID\"] = tmp\n",
    "\n",
    "                # Ethnic Group\n",
    "                if len(s.get(\"claims\", {}).get(\"P172\", [])) > 0:\n",
    "                    tmp = []\n",
    "                    for v in s[\"claims\"][\"P172\"]:\n",
    "                        if (\n",
    "                            v[\"mainsnak\"].get(\"datavalue\", {}).get(\"value\", {}).get(\"id\")\n",
    "                            is not None\n",
    "                        ):\n",
    "                            tmp.append(v[\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"])\n",
    "                    if len(tmp) > 0:\n",
    "                        s[\"ethnic_group\"] = tmp\n",
    "\n",
    "                # Religion\n",
    "                if len(s.get(\"claims\", {}).get(\"P140\", [])) > 0:\n",
    "                    tmp = []\n",
    "                    for v in s[\"claims\"][\"P140\"]:\n",
    "                        if (\n",
    "                            v[\"mainsnak\"].get(\"datavalue\", {}).get(\"value\", {}).get(\"id\")\n",
    "                            is not None\n",
    "                        ):\n",
    "                            tmp.append(v[\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"])\n",
    "                    if len(tmp) > 0:\n",
    "                        s[\"religion\"] = tmp\n",
    "\n",
    "                # Aliases. Removing leftovers and unnecessary attributes\n",
    "                if len(s.get(\"aliases\", {}).get(\"en\", [])) > 0:\n",
    "                    s[\"aliases\"] = [v[\"value\"] for v in s[\"aliases\"][\"en\"]]\n",
    "                elif s.get(\"aliases\") is not None:\n",
    "                    del s[\"aliases\"]\n",
    "                if s.get(\"descriptions\") is not None:\n",
    "                    del s[\"descriptions\"]\n",
    "                if s.get(\"sitelinks\") is not None:\n",
    "                    del s[\"sitelinks\"]\n",
    "                if s.get(\"claims\") is not None:\n",
    "                    del s[\"claims\"]\n",
    "\n",
    "                output_file.write(json.dumps(s, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
